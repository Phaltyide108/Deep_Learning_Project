{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10984963,"sourceType":"datasetVersion","datasetId":6836822},{"sourceId":11023144,"sourceType":"datasetVersion","datasetId":6863565},{"sourceId":286407,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":245450,"modelId":267060}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install rarfile","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T15:07:10.405173Z","iopub.execute_input":"2025-03-14T15:07:10.405495Z","iopub.status.idle":"2025-03-14T15:07:10.796574Z","shell.execute_reply.started":"2025-03-14T15:07:10.405465Z","shell.execute_reply":"2025-03-14T15:07:10.795696Z"}},"outputs":[{"name":"stdout","text":"^C\nTraceback (most recent call last):\n  File \"/usr/local/bin/pip3\", line 5, in <module>\n    from pip._internal.cli.main import main\n  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 11, in <module>\n    from pip._internal.cli.autocompletion import autocomplete\n  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/autocompletion.py\", line 10, in <module>\n    from pip._internal.cli.main_parser import create_main_parser\n  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main_parser.py\", line 9, in <module>\n    from pip._internal.build_env import get_runnable_pip\n  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/build_env.py\", line 19, in <module>\n    from pip._internal.cli.spinners import open_spinner\n  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/spinners.py\", line 9, in <module>\n    from pip._internal.utils.logging import get_indentation\n  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 13, in <module>\n    from pip._vendor.rich.console import (\n  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 51, in <module>\n    from ._log_render import FormatTimeCallable, LogRender\n  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/_log_render.py\", line 5, in <module>\n    from .text import Text, TextType\n  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/text.py\", line 23, in <module>\n    from .containers import Lines\n  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 879, in exec_module\n  File \"<frozen importlib._bootstrap_external>\", line 975, in get_code\n  File \"<frozen importlib._bootstrap_external>\", line 1074, in get_data\nKeyboardInterrupt\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import shutil\n# shutil.rmtree(\"/kaggle/working/rbc_dataset/slide14\")\nshutil.rmtree(\"/kaggle/working/rbc_dataset\")\nshutil.rmtree(\"/kaggle/working/temp\")\n# import os\n# # os.remove(\"/kaggle/working/rbc-dataset-slides-14-25.zip\")\n# # os.remove(\"/kaggle/working/dataset_slide1.zip\")\n# # os.remove(\"/kaggle/working/dataset_slide2.zip\")\n# # os.remove(\"/kaggle/working/dataset_slide3.zip\")\n# # os.remove(\"/kaggle/working/dataset_slide4.zip\")\n# # os.remove(\"/kaggle/working/dataset_slide5.zip\")\n# # os.remove(\"/kaggle/working/dataset_slide6.zip\")\n# os.remove(\"/kaggle/working/dataset_slide7.zip\")\n# os.remove(\"/kaggle/working/dataset_slide8.zip\")\n# os.remove(\"/kaggle/working/dataset_slide9.zip\")\n# os.remove(\"/kaggle/working/dataset_slide10.zip\")\n# os.remove(\"/kaggle/working/dataset_slide11.zip\")\n# os.remove(\"/kaggle/working/dataset_slide12.zip\")\n# os.remove(\"/kaggle/working/dataset_slide13.zip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T16:14:50.204495Z","iopub.execute_input":"2025-03-14T16:14:50.204835Z","iopub.status.idle":"2025-03-14T16:15:26.930973Z","shell.execute_reply.started":"2025-03-14T16:14:50.204807Z","shell.execute_reply":"2025-03-14T16:15:26.927652Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\n# Define the dataset folder path\ndataset_path = \"/kaggle/working/extracted_files/SEGMENTED - Slide 1\"\n\n# List all files in the dataset directory\nimage_files = [f for f in os.listdir(dataset_path) if f.lower().endswith(('png', 'jpg', 'jpeg'))]\n\n# Load the first image (change index to load another)\nif image_files:\n    image_path = os.path.join(dataset_path, image_files[0])\n    image = Image.open(image_path)\n\n    # Display the image\n    plt.imshow(image)\n    plt.axis(\"off\")  # Hide axes\n    plt.show()\nelse:\n    print(\"No images found in the dataset folder.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T15:07:10.805027Z","iopub.execute_input":"2025-03-14T15:07:10.805233Z","iopub.status.idle":"2025-03-14T15:07:10.846388Z","shell.execute_reply.started":"2025-03-14T15:07:10.805215Z","shell.execute_reply":"2025-03-14T15:07:10.844487Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-cb91b62698aa>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# List all files in the dataset directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mimage_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'jpeg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Load the first image (change index to load another)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/working/extracted_files/SEGMENTED - Slide 1'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/working/extracted_files/SEGMENTED - Slide 1'","output_type":"error"}],"execution_count":19},{"cell_type":"code","source":"import os\nimport zipfile\n\n# Define dataset path (Modify this based on your dataset name)\ndataset_zip = \"/kaggle/working/dataset_slide1.zip\"  # Change this!\ndataset_extracted = \"/kaggle/working/dataset_extracted\"\n\n# Create the extraction directory if not exists\nos.makedirs(dataset_extracted, exist_ok=True)\n\n# Extract the dataset\nwith zipfile.ZipFile(dataset_zip, 'r') as zip_ref:\n    zip_ref.extractall(dataset_extracted)\n\n# Print confirmation\nprint(f\"✅ Dataset extracted to: {dataset_extracted}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T15:07:10.847230Z","iopub.status.idle":"2025-03-14T15:07:10.847563Z","shell.execute_reply":"2025-03-14T15:07:10.847429Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport zipfile\n\n# Define the folder where ZIP files are stored\nzip_folder = \"/kaggle/working/dataset_extracted/Elsafty_RBCs_for_Segmentation_and_Detection_Slide_1\"  # Change this to your actual input folder path\n\n# Define the destination folder where extracted files will go\nextract_to = \"/kaggle/working/extracted_files\"  # Change if needed\n\n# Ensure the destination folder exists\nos.makedirs(extract_to, exist_ok=True)\n\n# List all ZIP files in the folder\nzip_files = [f for f in os.listdir(zip_folder) if f.endswith(\".zip\")]\n\n# Extract all ZIP files into the same folder\nfor zip_file in zip_files:\n    zip_path = os.path.join(zip_folder, zip_file)\n    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n        zip_ref.extractall(extract_to)\n\nprint(\"Extraction complete. Files are in:\", extract_to)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T15:07:10.848400Z","iopub.status.idle":"2025-03-14T15:07:10.848652Z","shell.execute_reply":"2025-03-14T15:07:10.848547Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!wget -O dataset_slide1.zip \"https://figshare.com/ndownloader/files/45801726\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T15:07:10.849310Z","iopub.status.idle":"2025-03-14T15:07:10.849583Z","shell.execute_reply":"2025-03-14T15:07:10.849471Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!wget -O dataset_slide1.zip \"https://figshare.com/ndownloader/files/45801726\"\n!wget -O dataset_slide2.zip \"https://figshare.com/ndownloader/files/46130826\"\n!wget -O dataset_slide3.zip \"https://figshare.com/ndownloader/files/45804540\"\n!wget -O dataset_slide4.zip \"https://figshare.com/ndownloader/files/46132794\"\n!wget -O dataset_slide5.zip \"https://figshare.com/ndownloader/files/45805089\"\n!wget -O dataset_slide6.zip \"https://figshare.com/ndownloader/files/45806130\"\n!wget -O dataset_slide7.zip \"https://figshare.com/ndownloader/files/45815796\"\n!wget -O dataset_slide8.zip \"https://figshare.com/ndownloader/files/45819264\"\n!wget -O dataset_slide9.zip \"https://figshare.com/ndownloader/files/45820893\"\n!wget -O dataset_slide10.zip \"https://figshare.com/ndownloader/files/45814704\"\n!wget -O dataset_slide11.zip \"https://figshare.com/ndownloader/files/45815424\"\n!wget -O dataset_slide12.zip \"https://figshare.com/ndownloader/files/46125228\"\n!wget -O dataset_slide13.zip \"https://figshare.com/ndownloader/files/46127385\"\n# !wget -O dataset_slide14.zip \"https://figshare.com/ndownloader/files/46134240\"\n# !wget -O dataset_slide15.zip \"https://figshare.com/ndownloader/files/46134870\"\n# !wget -O dataset_slide16.zip \"https://figshare.com/ndownloader/files/45814155\"\n# !wget -O dataset_slide17.zip \"https://figshare.com/ndownloader/files/46129752\"\n# !wget -O dataset_slide18.zip \"https://figshare.com/ndownloader/files/46129953\"\n# !wget -O dataset_slide19.zip \"https://figshare.com/ndownloader/files/46129062\"\n# !wget -O dataset_slide20.zip \"https://figshare.com/ndownloader/files/46127448\"\n# !wget -O dataset_slide21.zip \"https://figshare.com/ndownloader/files/46127478\"\n# !wget -O dataset_slide22.zip \"https://figshare.com/ndownloader/files/46135149\"\n# !wget -O dataset_slide23.zip \"https://figshare.com/ndownloader/files/46127790\"\n# !wget -O dataset_slide24.zip \"https://figshare.com/ndownloader/files/46127892\"\n# !wget -O dataset_slide25.zip \"https://figshare.com/ndownloader/files/45812706\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T15:07:10.851022Z","iopub.status.idle":"2025-03-14T15:07:10.851349Z","shell.execute_reply":"2025-03-14T15:07:10.851234Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"beow code is for extracting and relocating code","metadata":{}},{"cell_type":"code","source":"import os\nimport zipfile\nimport shutil\n\nbase_dir = \"/kaggle/working\"\noutput_dir = \"/kaggle/working/rbc_dataset\"\ntemp_dir = \"/kaggle/working/temp\"\n\nos.makedirs(output_dir, exist_ok=True)\nos.makedirs(temp_dir, exist_ok=True)\n\nfor i in range(1, 14):\n    slide_zip_path = os.path.join(base_dir, f\"dataset_slide{i}.zip\")\n    if not os.path.exists(slide_zip_path):\n        print(f\"Skipping {slide_zip_path}, not found.\")\n        continue\n\n    temp_extract_path = os.path.join(temp_dir, f\"dataset_slide{i}\")\n    os.makedirs(temp_extract_path, exist_ok=True)\n\n    # Extract outer zip\n    with zipfile.ZipFile(slide_zip_path, 'r') as slide_zip:\n        slide_zip.extractall(temp_extract_path)\n    print(f\"Extracted {slide_zip_path} -> {temp_extract_path}\")\n\n    # Delete outer zip\n    try:\n        os.remove(slide_zip_path)\n        print(f\"Deleted {slide_zip_path}\")\n    except Exception as e:\n        print(f\"Could not delete {slide_zip_path}: {e}\")\n\n    # Process inner zips (search recursively)\n    for root, _, files in os.walk(temp_extract_path):\n        for file in files:\n            if not file.endswith(\".zip\"):\n                continue  # Skip non-zip files\n\n            inner_zip_path = os.path.join(root, file)\n\n            # Delete Segmented zips\n            if \"SEGMENTED\" in file:\n                os.remove(inner_zip_path)\n                print(f\"Deleted {inner_zip_path} (Segmented)\")\n                continue\n\n            # Process Cropped/Mask\n            if \"CROPPED\" in file or \"Masks\" in file:\n                # Include slide number in output path\n                final_extract_path = os.path.join(\n                    output_dir, \n                    f\"slide{i}\", \n                    file.replace(\".zip\", \"\")\n                )\n                os.makedirs(final_extract_path, exist_ok=True)\n\n                # Extract and delete\n                with zipfile.ZipFile(inner_zip_path, 'r') as inner_zip_file:\n                    inner_zip_file.extractall(final_extract_path)\n                print(f\"Extracted {file} -> {final_extract_path}\")\n                os.remove(inner_zip_path)\n                print(f\"Deleted {inner_zip_path}\")\n\n    # Cleanup\n    shutil.rmtree(temp_extract_path)\n    print(f\"Deleted temporary folder {temp_extract_path}\")\n\nprint(\"Extraction complete. Merged dataset at:\", output_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T15:07:10.852571Z","iopub.status.idle":"2025-03-14T15:07:10.852997Z","shell.execute_reply":"2025-03-14T15:07:10.852832Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install kaggle","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T15:07:10.853996Z","iopub.status.idle":"2025-03-14T15:07:10.854238Z","shell.execute_reply":"2025-03-14T15:07:10.854139Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Below code is for uploading it to kaggle dataset","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\n\n# Define paths\nbase_dir = \"/kaggle/working\"\nupload_dir = \"/kaggle/working/upload_to_kaggle_dataset\"\n\n# Create the upload directory\nos.makedirs(upload_dir, exist_ok=True)\n\n# Move zip files from slide 14 to 25 into the upload directory\nfor i in range(14, 26):\n    slide_zip_path = os.path.join(base_dir, f\"dataset_slide{i}.zip\")\n    if os.path.exists(slide_zip_path):\n        shutil.move(slide_zip_path, upload_dir)\n        print(f\"Moved {slide_zip_path} to {upload_dir}\")\n    else:\n        print(f\"Skipping {slide_zip_path}, not found.\")\n\nprint(\"All zip files moved to:\", upload_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T15:07:10.855165Z","iopub.status.idle":"2025-03-14T15:07:10.855410Z","shell.execute_reply":"2025-03-14T15:07:10.855309Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\n# Compress the upload directory\nshutil.make_archive(\"/kaggle/working/rbc_slides_14_25\", 'zip', upload_dir)\nprint(\"Compressed folder created: /kaggle/working/rbc_slides_14_25.zip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T15:07:10.856088Z","iopub.status.idle":"2025-03-14T15:07:10.856405Z","shell.execute_reply":"2025-03-14T15:07:10.856292Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'rbc_slides_14_25.zip')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T15:07:10.858181Z","iopub.status.idle":"2025-03-14T15:07:10.858586Z","shell.execute_reply":"2025-03-14T15:07:10.858403Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\nshutil.copy(\"/kaggle/input/kaggle_json_file/other/default/1/kaggle.json\", \"/root/.kaggle/kaggle.json\")\n!chmod 600 /root/.kaggle/kaggle.json\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T15:07:10.859519Z","iopub.status.idle":"2025-03-14T15:07:10.859932Z","shell.execute_reply":"2025-03-14T15:07:10.859754Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls /kaggle/input/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T15:07:10.860940Z","iopub.status.idle":"2025-03-14T15:07:10.861358Z","shell.execute_reply":"2025-03-14T15:07:10.861155Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Below code is modified version (not useful) of extarction and relocation of dataset code","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\n\n# Define paths\ninput_dir = \"/kaggle/input/rbc-dataset-slides-14-25\"  # Read-only dataset\noutput_dir = \"/kaggle/working/rbc_dataset\"  # Output directory\n\nos.makedirs(output_dir, exist_ok=True)\n\ndef copy_files(src_folder, dst_folder, folder_type=\"CROPPED\"):\n    \"\"\"Copy files from src_folder to dst_folder, preserving filenames.\"\"\"\n    if not os.path.exists(src_folder):\n        print(f\"Skipping {folder_type} folder: {src_folder} not found.\")\n        return\n\n    # Handle nested folders (e.g., CROPPED - Slide 14/CROPPED - Slide 14)\n    for root, _, files in os.walk(src_folder):\n        for file in files:\n            src_path = os.path.join(root, file)\n            dst_path = os.path.join(dst_folder, file)\n            \n            # Skip existing files to avoid overwriting\n            if os.path.exists(dst_path):\n                print(f\"Skipping existing file: {dst_path}\")\n                continue\n            \n            # Copy the file\n            try:\n                shutil.copy2(src_path, dst_folder)\n                # print(f\"Copied {file} to {dst_folder}\")\n            except Exception as e:\n                print(f\"Failed to copy {file}: {e}\")\n\n# Process slides 14-25\nfor i in range(14, 26):\n    print(f\"\\nProcessing slide {i}...\")\n    slide_folder = os.path.join(input_dir, f\"dataset_slide{i}\", f\"Elsafty_RBCs_for_Segmentation_and_Detection_Slide_{i}\")\n    \n    if not os.path.exists(slide_folder):\n        print(f\"Skipping slide {i}, folder not found: {slide_folder}\")\n        continue\n\n    # Define paths for CROPPED and Masks\n    cropped_src = os.path.join(slide_folder, f\"CROPPED - Slide {i}\")\n    masks_src = os.path.join(slide_folder, f\"Masks - Slide {i}\")\n\n    # Create output directories\n    cropped_dst = os.path.join(output_dir, f\"slide{i}\", \"CROPPED\")\n    masks_dst = os.path.join(output_dir, f\"slide{i}\", \"Masks\")\n    os.makedirs(cropped_dst, exist_ok=True)\n    os.makedirs(masks_dst, exist_ok=True)\n\n    # Copy CROPPED files\n    # print(f\"Copying CROPPED files for slide {i}...\")\n    copy_files(cropped_src, cropped_dst, \"CROPPED\")\n\n    # Copy Masks files\n    # print(f\"Copying Masks files for slide {i}...\")\n    copy_files(masks_src, masks_dst, \"Masks\")\n\nprint(\"\\nProcessing complete! Output directory:\", output_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T18:40:04.035410Z","iopub.execute_input":"2025-03-14T18:40:04.035719Z"}},"outputs":[{"name":"stdout","text":"\nProcessing slide 14...\n\nProcessing slide 15...\n\nProcessing slide 16...\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"Below code is for only wbc segmentation code","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n\n# Set paths\nbase_path = \"/kaggle/input/segmentation-wbc\"\ntrain_img_dir = os.path.join(base_path, \"Train_bmp\")\ntrain_mask_dir = os.path.join(base_path, \"Train_GT_bmp\")\ntest_img_dir = os.path.join(base_path, \"Test_bmp\")\ntest_mask_dir = os.path.join(base_path, \"Test_GT_bmp\")\n\n# Image parameters\nIMG_HEIGHT, IMG_WIDTH = 256, 256  # Resize all images to this shape\nIMG_CHANNELS = 3  # RGB images\n\n# Function to load images\ndef load_images_from_folder(folder, target_size=(IMG_HEIGHT, IMG_WIDTH)):\n    images = []\n    filenames = sorted(os.listdir(folder))  # Sort to match with masks\n    for filename in filenames:\n        img_path = os.path.join(folder, filename)\n        img = load_img(img_path, target_size=target_size)  # Load & resize\n        img = img_to_array(img) / 255.0  # Normalize\n        images.append(img)\n    return np.array(images), filenames\n\n# Function to load masks (convert to binary)\ndef load_masks_from_folder(folder, target_size=(IMG_HEIGHT, IMG_WIDTH)):\n    masks = []\n    filenames = sorted(os.listdir(folder))\n    for filename in filenames:\n        mask_path = os.path.join(folder, filename)\n        mask = load_img(mask_path, color_mode=\"grayscale\", target_size=target_size)  # Load grayscale mask\n        mask = img_to_array(mask) / 255.0  # Normalize mask\n        mask = (mask > 0.5).astype(np.uint8)  # Convert to binary (0 or 1)\n        masks.append(mask)\n    return np.array(masks), filenames\n\n# Load train images and masks\nX_train, train_filenames = load_images_from_folder(train_img_dir)\nY_train, mask_filenames = load_masks_from_folder(train_mask_dir)\n\n# Ensure images and masks match\nassert train_filenames == mask_filenames, \"Mismatch between images and masks!\"\n\n# Split into training and validation sets (80-20 split)\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)\n\nprint(f\"Train shape: {X_train.shape}, {Y_train.shape}\")\nprint(f\"Validation shape: {X_val.shape}, {Y_val.shape}\")\n\n# U-Net Model\ndef build_unet_model(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)):\n    inputs = layers.Input(input_shape)\n\n    # Encoder (Downsampling)\n    c1 = layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(inputs)\n    c1 = layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(c1)\n    p1 = layers.MaxPooling2D((2, 2))(c1)\n\n    c2 = layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(p1)\n    c2 = layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(c2)\n    p2 = layers.MaxPooling2D((2, 2))(c2)\n\n    # Bottleneck\n    c3 = layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(p2)\n    c3 = layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(c3)\n\n    # Decoder (Upsampling)\n    u1 = layers.UpSampling2D((2, 2))(c3)\n    u1 = layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(u1)\n    u1 = layers.Concatenate()([u1, c2])\n\n    u2 = layers.UpSampling2D((2, 2))(u1)\n    u2 = layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(u2)\n    u2 = layers.Concatenate()([u2, c1])\n\n    outputs = layers.Conv2D(1, (1, 1), activation=\"sigmoid\")(u2)  # Sigmoid activation for binary segmentation\n\n    model = keras.Model(inputs, outputs, name=\"U-Net\")\n    return model\n\n# Compile the model\nmodel = build_unet_model()\nmodel.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\nmodel.summary()\n\n# Train the model\nhistory = model.fit(\n    X_train, Y_train,\n    validation_data=(X_val, Y_val),\n    epochs=20,\n    batch_size=8\n)\n\n# Load test images and masks\nX_test, test_filenames = load_images_from_folder(test_img_dir)\nY_test, test_mask_filenames = load_masks_from_folder(test_mask_dir)\n\n# Ensure test images and masks match\nassert test_filenames == test_mask_filenames, \"Mismatch between test images and masks!\"\n\n# Evaluate on test set\ntest_loss, test_acc = model.evaluate(X_test, Y_test)\nprint(f\"Test Accuracy: {test_acc:.4f}\")\n\n# Predict masks on test set\npred_masks = model.predict(X_test)\n\n# Visualizing results\ndef display_predictions(index):\n    fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n\n    ax[0].imshow(X_test[index])\n    ax[0].set_title(\"Original Image\")\n\n    ax[1].imshow(Y_test[index].squeeze(), cmap=\"gray\")\n    ax[1].set_title(\"Ground Truth Mask\")\n\n    ax[2].imshow(pred_masks[index].squeeze(), cmap=\"gray\")\n    ax[2].set_title(\"Predicted Mask\")\n\n    plt.show()\n\n# Show sample predictions\nfor i in range(5):\n    display_predictions(i)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T15:07:10.863529Z","iopub.status.idle":"2025-03-14T15:07:10.863812Z","shell.execute_reply":"2025-03-14T15:07:10.863671Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save model in HDF5 format\nmodel.save(\"/kaggle/working/unet_wbc_segmentation.h5\")\n\n# Save model in TensorFlow SavedModel format (alternative)\n# model.save(\"/kaggle/working/unet_wbc_segmentation\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T15:07:10.864560Z","iopub.status.idle":"2025-03-14T15:07:10.864838Z","shell.execute_reply":"2025-03-14T15:07:10.864699Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install tensorflow keras numpy opencv-python matplotlib","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T15:07:10.866480Z","iopub.status.idle":"2025-03-14T15:07:10.866887Z","shell.execute_reply":"2025-03-14T15:07:10.866732Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Below code is for both rbc and wbc segmentation code ","metadata":{}},{"cell_type":"code","source":"import os\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\n\n# Directories for WBC dataset\nWBC_TRAIN_IMG_DIR = \"/kaggle/input/segmentation-wbc/Train_bmp\"\nWBC_TRAIN_MASK_DIR = \"/kaggle/input/segmentation-wbc/Train_GT_bmp\"\nWBC_TEST_IMG_DIR = \"/kaggle/input/segmentation-wbc/Test_bmp\"\nWBC_TEST_MASK_DIR = \"/kaggle/input/segmentation-wbc/Test_GT_bmp\"\n\n# Directories for RBC dataset\nRBC_BASE_DIR = \"/kaggle/working/rbc_dataset\"\nVALID_SLIDES = [f\"slide{i}\" for i in range(1, 14)]  # Only slides 1 to 13\n\n# Image dimensions\nIMG_SIZE = (256, 256)\n\n# Function to get image and mask paths\ndef get_file_paths(image_dir, mask_dir):\n    image_paths = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(('.bmp', '.png', '.jpg'))])\n    mask_paths = sorted([os.path.join(mask_dir, f) for f in os.listdir(mask_dir) if f.endswith(('.bmp', '.png', '.jpg'))])\n    return image_paths, mask_paths\n\ndef load_and_preprocess(img_path, mask_path):\n    # Read image file\n    img = tf.io.read_file(img_path)\n    img = tf.image.decode_image(img)  # Do not set channels to allow auto-detection\n    img.set_shape([None, None, None])  # Ensure TensorFlow can infer shape\n    if tf.shape(img)[-1] == 1:  # If grayscale, convert to RGB\n        img = tf.image.grayscale_to_rgb(img)\n    img = tf.image.resize(img, IMG_SIZE)\n    img = tf.cast(img, tf.float32) / 255.0  # Normalize to [0,1]\n\n    # Read mask file\n    mask_content = tf.io.read_file(mask_path)\n    mask = tf.image.decode_image(mask_content)\n    mask.set_shape([None, None, None])  # Ensure TensorFlow can infer shape\n    if tf.shape(mask)[-1] == 3:  # If mask has 3 channels, convert to grayscale\n        mask = tf.image.rgb_to_grayscale(mask)\n    mask = tf.image.resize(mask, IMG_SIZE)\n    mask = tf.cast(mask, tf.float32) / 255.0  # Normalize to [0,1]\n\n    return img, mask\n\n\n# Function to create a TensorFlow dataset\ndef create_dataset(image_paths, mask_paths, batch_size=512):\n    dataset = tf.data.Dataset.from_tensor_slices((image_paths, mask_paths))\n    dataset = dataset.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n    return dataset\n\n# Load WBC paths\nwbc_train_img_paths, wbc_train_mask_paths = get_file_paths(WBC_TRAIN_IMG_DIR, WBC_TRAIN_MASK_DIR)\nwbc_test_img_paths, wbc_test_mask_paths = get_file_paths(WBC_TEST_IMG_DIR, WBC_TEST_MASK_DIR)\n\n# Load RBC paths\nrbc_train_img_paths, rbc_train_mask_paths = [], []\nfor slide in VALID_SLIDES:\n    slide_number = slide.replace(\"slide\", \"\")\n    img_dir = os.path.join(RBC_BASE_DIR, slide, f\"CROPPED - Slide {slide_number}\", f\"CROPPED - Slide {slide_number}\")\n    mask_dir = os.path.join(RBC_BASE_DIR, slide, f\"Masks - Slide {slide_number}\", f\"Masks - Slide {slide_number}\")\n    if os.path.exists(img_dir) and os.path.exists(mask_dir):\n        imgs, masks = get_file_paths(img_dir, mask_dir)\n        rbc_train_img_paths.extend(imgs)\n        rbc_train_mask_paths.extend(masks)\n\n# Combine WBC + RBC paths\nall_train_img_paths = wbc_train_img_paths + rbc_train_img_paths\nall_train_mask_paths = wbc_train_mask_paths + rbc_train_mask_paths\n\n# Split into training and validation sets\ntrain_img_paths, val_img_paths, train_mask_paths, val_mask_paths = train_test_split(\n    all_train_img_paths, all_train_mask_paths, test_size=0.2, random_state=42\n)\n\n# Create datasets\ntrain_dataset = create_dataset(train_img_paths, train_mask_paths, batch_size=8)\nval_dataset = create_dataset(val_img_paths, val_mask_paths, batch_size=8)\ntest_dataset = create_dataset(wbc_test_img_paths, wbc_test_mask_paths, batch_size=8)\n\n# Build a simple U-Net-like CNN model\ndef build_model():\n    model = Sequential([\n        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 3)),\n        MaxPooling2D((2, 2)),\n        Conv2D(64, (3, 3), activation='relu', padding='same'),\n        MaxPooling2D((2, 2)),\n        UpSampling2D((2, 2)),\n        Conv2D(64, (3, 3), activation='relu', padding='same'),\n        UpSampling2D((2, 2)),\n        Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n    ])\n    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n    return model\n\n# Train model\nmodel = build_model()\nhistory = model.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=10,\n    steps_per_epoch=len(train_img_paths) // 8,\n    validation_steps=len(val_img_paths) // 8\n)\n\n# Evaluate on WBC test set\ntest_loss, test_acc = model.evaluate(test_dataset)\nprint(f\"WBC Test Accuracy: {test_acc:.4f}\")\n\n# Predict on WBC test set\npred_masks = model.predict(test_dataset)\n\n# Visualization\nimport matplotlib.pyplot as plt\n\ndef display_predictions(index):\n    fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n    ax[0].imshow(X_test[index])\n    ax[0].set_title(\"Original WBC Test\")\n    ax[1].imshow(Y_test[index].squeeze(), cmap=\"gray\")\n    ax[1].set_title(\"Ground Truth Mask\")\n    ax[2].imshow(pred_masks[index].squeeze(), cmap=\"gray\")\n    ax[2].set_title(\"Predicted Mask\")\n    plt.show()\n\nfor i in range(3):\n    display_predictions(i)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T15:07:10.867578Z","iopub.status.idle":"2025-03-14T15:07:10.868012Z","shell.execute_reply":"2025-03-14T15:07:10.867805Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Below code is for only rbc segmentation\n","metadata":{}},{"cell_type":"code","source":"import os\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\n\n# Directories for RBC dataset\nRBC_BASE_DIR = \"/kaggle/working/rbc_dataset\"\nVALID_SLIDES = [f\"slide{i}\" for i in range(1, 26)]  # Only slides 1 to 13\n\n# Image dimensions\nIMG_SIZE = (256, 256)\n\n# Function to get image and mask paths\ndef get_file_paths(image_dir, mask_dir):\n    image_paths = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(('.bmp', '.png', '.jpg'))])\n    mask_paths = sorted([os.path.join(mask_dir, f) for f in os.listdir(mask_dir) if f.endswith(('.bmp', '.png', '.jpg'))])\n    return image_paths, mask_paths\n\ndef load_and_preprocess(img_path, mask_path):\n    # Read image file\n    img = tf.io.read_file(img_path)\n    img = tf.image.decode_image(img)  # Do not set channels to allow auto-detection\n    img.set_shape([None, None, None])  # Ensure TensorFlow can infer shape\n    if tf.shape(img)[-1] == 1:  # If grayscale, convert to RGB\n        img = tf.image.grayscale_to_rgb(img)\n    img = tf.image.resize(img, IMG_SIZE)\n    img = tf.cast(img, tf.float32) / 255.0  # Normalize to [0,1]\n\n    # Read mask file\n    mask_content = tf.io.read_file(mask_path)\n    mask = tf.image.decode_image(mask_content)\n    mask.set_shape([None, None, None])  # Ensure TensorFlow can infer shape\n    if tf.shape(mask)[-1] == 3:  # If mask has 3 channels, convert to grayscale\n        mask = tf.image.rgb_to_grayscale(mask)\n    mask = tf.image.resize(mask, IMG_SIZE)\n    mask = tf.cast(mask, tf.float32) / 255.0  # Normalize to [0,1]\n\n    return img, mask\n\n# Function to create a TensorFlow dataset\ndef create_dataset(image_paths, mask_paths, batch_size=512):\n    dataset = tf.data.Dataset.from_tensor_slices((image_paths, mask_paths))\n    dataset = dataset.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n    return dataset\n\n# Load RBC paths\nrbc_train_img_paths, rbc_train_mask_paths = [], []\nfor slide in VALID_SLIDES:\n    slide_number = slide.replace(\"slide\", \"\")\n    img_dir = os.path.join(RBC_BASE_DIR, slide, f\"CROPPED - Slide {slide_number}\", f\"CROPPED - Slide {slide_number}\")\n    mask_dir = os.path.join(RBC_BASE_DIR, slide, f\"Masks - Slide {slide_number}\", f\"Masks - Slide {slide_number}\")\n    if os.path.exists(img_dir) and os.path.exists(mask_dir):\n        imgs, masks = get_file_paths(img_dir, mask_dir)\n        rbc_train_img_paths.extend(imgs)\n        rbc_train_mask_paths.extend(masks)\n\n# Split into training and validation sets\ntrain_img_paths, val_img_paths, train_mask_paths, val_mask_paths = train_test_split(\n    rbc_train_img_paths, rbc_train_mask_paths, test_size=0.2, random_state=42\n)\n\n# Create datasets\ntrain_dataset = create_dataset(train_img_paths, train_mask_paths, batch_size=8)\nval_dataset = create_dataset(val_img_paths, val_mask_paths, batch_size=8)\n\n# Build a simple U-Net-like CNN model\ndef build_model():\n    model = Sequential([\n        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 3)),\n        MaxPooling2D((2, 2)),\n        Conv2D(64, (3, 3), activation='relu', padding='same'),\n        MaxPooling2D((2, 2)),\n        UpSampling2D((2, 2)),\n        Conv2D(64, (3, 3), activation='relu', padding='same'),\n        UpSampling2D((2, 2)),\n        Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n    ])\n    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n    return model\n\n# Train model\nmodel = build_model()\nhistory = model.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=5,\n    steps_per_epoch=len(train_img_paths) // 8,\n    validation_steps=len(val_img_paths) // 8\n)\n\n# Evaluate on RBC validation set\ntest_loss, test_acc = model.evaluate(val_dataset)\nprint(f\"RBC Validation Accuracy: {test_acc:.4f}\")\n\n# Predict on RBC validation set\npred_masks = model.predict(val_dataset)\n\n# Visualization\nimport matplotlib.pyplot as plt\n\ndef display_predictions(index):\n    fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n    ax[0].imshow(X_test[index])\n    ax[0].set_title(\"Original RBC Image\")\n    ax[1].imshow(Y_test[index].squeeze(), cmap=\"gray\")\n    ax[1].set_title(\"Ground Truth Mask\")\n    ax[2].imshow(pred_masks[index].squeeze(), cmap=\"gray\")\n    ax[2].set_title(\"Predicted Mask\")\n    plt.show()\n\nfor i in range(3):\n    display_predictions(i)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T15:07:10.868589Z","iopub.status.idle":"2025-03-14T15:07:10.868871Z","shell.execute_reply":"2025-03-14T15:07:10.868746Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"one for 1to 13and 14 to 25","metadata":{}},{"cell_type":"code","source":"import os\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D\nfrom tensorflow.keras.optimizers import Nadam  # Changed from Adam to Nadam\nfrom sklearn.model_selection import train_test_split\n\n# Directories for RBC dataset\nRBC_BASE_DIR = \"/kaggle/working/rbc_dataset\"\n\n# Image dimensions\nIMG_SIZE = (512, 512)\n\n# Function to get image and mask paths\ndef get_file_paths(image_dir, mask_dir):\n    image_paths = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(('.bmp', '.png', '.jpg'))])\n    mask_paths = sorted([os.path.join(mask_dir, f) for f in os.listdir(mask_dir) if f.endswith(('.bmp', '.png', '.jpg'))])\n    return image_paths, mask_paths\n\ndef load_and_preprocess(img_path, mask_path):\n    # Read image file\n    img = tf.io.read_file(img_path)\n    img = tf.image.decode_image(img)  # Do not set channels to allow auto-detection\n    img.set_shape([None, None, None])  # Ensure TensorFlow can infer shape\n    if tf.shape(img)[-1] == 1:  # If grayscale, convert to RGB\n        img = tf.image.grayscale_to_rgb(img)\n    img = tf.image.resize(img, IMG_SIZE)\n    img = tf.cast(img, tf.float32) / 255.0  # Normalize to [0,1]\n\n    # Read mask file\n    mask_content = tf.io.read_file(mask_path)\n    mask = tf.image.decode_image(mask_content)\n    mask.set_shape([None, None, None])  # Ensure TensorFlow can infer shape\n    if tf.shape(mask)[-1] == 3:  # If mask has 3 channels, convert to grayscale\n        mask = tf.image.rgb_to_grayscale(mask)\n    mask = tf.image.resize(mask, IMG_SIZE)\n    mask = tf.cast(mask, tf.float32) / 255.0  # Normalize to [0,1]\n\n    return img, mask\n\n# Function to create a TensorFlow dataset\ndef create_dataset(image_paths, mask_paths, batch_size=512):\n    dataset = tf.data.Dataset.from_tensor_slices((image_paths, mask_paths))\n    dataset = dataset.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n    return dataset\n\n# Function to load paths for a specific range of slides\ndef load_slide_paths(slide_range):\n    img_paths, mask_paths = [], []\n    for slide in slide_range:\n        slide_number = slide.replace(\"slide\", \"\")\n        img_dir = os.path.join(RBC_BASE_DIR, slide, f\"CROPPED - Slide {slide_number}\", f\"CROPPED - Slide {slide_number}\")\n        mask_dir = os.path.join(RBC_BASE_DIR, slide, f\"Masks - Slide {slide_number}\", f\"Masks - Slide {slide_number}\")\n        if os.path.exists(img_dir) and os.path.exists(mask_dir):\n            imgs, masks = get_file_paths(img_dir, mask_dir)\n            img_paths.extend(imgs)\n            mask_paths.extend(masks)\n    return img_paths, mask_paths\n\n# Build a simple U-Net-like CNN model\ndef build_model():\n    model = Sequential([\n        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 3)),\n        MaxPooling2D((2, 2)),\n        Conv2D(64, (3, 3), activation='relu', padding='same'),\n        MaxPooling2D((2, 2)),\n        UpSampling2D((2, 2)),\n        Conv2D(64, (3, 3), activation='relu', padding='same'),\n        UpSampling2D((2, 2)),\n        Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n    ])\n    model.compile(optimizer=Nadam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])  # Changed from Adam to Nadam\n    return model\n\n# Train on slides 1-13\nprint(\"Training on slides 1-13...\")\nslide_range_1_13 = [f\"slide{i}\" for i in range(1, 14)]\ntrain_img_paths_1_13, train_mask_paths_1_13 = load_slide_paths(slide_range_1_13)\n\n# Split into training and validation sets\ntrain_img_paths, val_img_paths, train_mask_paths, val_mask_paths = train_test_split(\n    train_img_paths_1_13, train_mask_paths_1_13, test_size=0.2, random_state=42\n)\n\n# Create datasets\ntrain_dataset = create_dataset(train_img_paths, train_mask_paths, batch_size=8)\nval_dataset = create_dataset(val_img_paths, val_mask_paths, batch_size=8)\n\n# Build and train the model\nmodel = build_model()\nhistory = model.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=3,\n    steps_per_epoch=len(train_img_paths) // 60,\n    validation_steps=len(val_img_paths) // 60\n)\n\n# Save the model\nmodel.save(\"/kaggle/working/rbc_model_slides_1_13.h5\")\nprint(\"Model saved for slides 1-13.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T15:20:12.610361Z","iopub.execute_input":"2025-03-14T15:20:12.610718Z","iopub.status.idle":"2025-03-14T16:09:08.272844Z","shell.execute_reply.started":"2025-03-14T15:20:12.610680Z","shell.execute_reply":"2025-03-14T16:09:08.271785Z"}},"outputs":[{"name":"stdout","text":"Training on slides 1-13...\nEpoch 1/3\n\u001b[1m8715/8715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m991s\u001b[0m 113ms/step - accuracy: 0.8723 - loss: 0.2564 - val_accuracy: 0.8738 - val_loss: 0.2488\nEpoch 2/3\n\u001b[1m8715/8715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m972s\u001b[0m 111ms/step - accuracy: 0.8729 - loss: 0.2502 - val_accuracy: 0.8736 - val_loss: 0.2486\nEpoch 3/3\n\u001b[1m8715/8715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m965s\u001b[0m 111ms/step - accuracy: 0.8728 - loss: 0.2491 - val_accuracy: 0.8725 - val_loss: 0.2486\nModel saved for slides 1-13.\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T17:30:16.369818Z","iopub.execute_input":"2025-03-14T17:30:16.370143Z","iopub.status.idle":"2025-03-14T17:30:16.382405Z","shell.execute_reply.started":"2025-03-14T17:30:16.370114Z","shell.execute_reply":"2025-03-14T17:30:16.381517Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"import os\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D\nfrom tensorflow.keras.optimizers import Nadam\nfrom sklearn.model_selection import train_test_split\n\n# Directories for RBC dataset\nRBC_BASE_DIR = \"/kaggle/working/rbc_dataset\"\n\n# Image dimensions\nIMG_SIZE = (512, 512)\n\n# Function to get image and mask paths\ndef get_file_paths(image_dir, mask_dir):\n    image_paths = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(('.bmp', '.png', '.jpg'))])\n    mask_paths = sorted([os.path.join(mask_dir, f) for f in os.listdir(mask_dir) if f.endswith(('.bmp', '.png', '.jpg'))])\n    return image_paths, mask_paths\n\ndef load_and_preprocess(img_path, mask_path):\n    # Read image file\n    img = tf.io.read_file(img_path)\n    img = tf.image.decode_image(img)  # Do not set channels to allow auto-detection\n    img.set_shape([None, None, None])  # Ensure TensorFlow can infer shape\n    if tf.shape(img)[-1] == 1:  # If grayscale, convert to RGB\n        img = tf.image.grayscale_to_rgb(img)\n    img = tf.image.resize(img, IMG_SIZE)\n    img = tf.cast(img, tf.float32) / 255.0  # Normalize to [0,1]\n\n    # Read mask file\n    mask_content = tf.io.read_file(mask_path)\n    mask = tf.image.decode_image(mask_content)\n    mask.set_shape([None, None, None])  # Ensure TensorFlow can infer shape\n    if tf.shape(mask)[-1] == 3:  # If mask has 3 channels, convert to grayscale\n        mask = tf.image.rgb_to_grayscale(mask)\n    mask = tf.image.resize(mask, IMG_SIZE)\n    mask = tf.cast(mask, tf.float32) / 255.0  # Normalize to [0,1]\n\n    return img, mask\n\n# Function to create a TensorFlow dataset\ndef create_dataset(image_paths, mask_paths, batch_size=512):\n    dataset = tf.data.Dataset.from_tensor_slices((image_paths, mask_paths))\n    dataset = dataset.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n    return dataset\n\n# Function to load paths for a specific range of slides\ndef load_slide_paths(slide_range):\n    img_paths, mask_paths = [], []\n    for slide in slide_range:\n        img_dir = os.path.join(RBC_BASE_DIR, slide, \"CROPPED\")  # Updated path\n        mask_dir = os.path.join(RBC_BASE_DIR, slide, \"Masks\")  # Updated path\n        if os.path.exists(img_dir) and os.path.exists(mask_dir):\n            imgs, masks = get_file_paths(img_dir, mask_dir)\n            img_paths.extend(imgs)\n            mask_paths.extend(masks)\n        else:\n            print(f\"Skipping {slide}: directories not found.\")\n    return img_paths, mask_paths\n\n# Train on slides 14-25\nprint(\"Training on slides 14-25...\")\nslide_range_14_25 = [f\"slide{i}\" for i in range(14, 26)]\ntrain_img_paths_14_25, train_mask_paths_14_25 = load_slide_paths(slide_range_14_25)\n\n# Print debugging information\nprint(f\"Number of images: {len(train_img_paths_14_25)}\")\nprint(f\"Number of masks: {len(train_mask_paths_14_25)}\")\nprint(\"Sample image paths:\", train_img_paths_14_25[:5])\nprint(\"Sample mask paths:\", train_mask_paths_14_25[:5])\n\n# Split into training and validation sets\ntrain_img_paths, val_img_paths, train_mask_paths, val_mask_paths = train_test_split(\n    train_img_paths_14_25, train_mask_paths_14_25, test_size=0.2, random_state=42\n)\n\n# Create datasets\ntrain_dataset = create_dataset(train_img_paths, train_mask_paths, batch_size=8)\nval_dataset = create_dataset(val_img_paths, val_mask_paths, batch_size=8)\n\n# Load the saved model\nmodel = load_model(\"/kaggle/input/rbc_model_slides_1_13.h5/tensorflow2/default/1/rbc_model_slides_1_13.h5\")\n\n# Reinitialize the optimizer\nmodel.compile(optimizer=Nadam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n\n# Continue training on slides 14-25\nhistory = model.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=2,\n    steps_per_epoch=len(train_img_paths) // 60,\n    validation_steps=len(val_img_paths) // 60\n)\n\n# Save the final model\nmodel.save(\"/kaggle/working/rbc_model_final.h5\")\nprint(\"Final model saved.\")\n\n# Evaluate on the validation set\ntest_loss, test_acc = model.evaluate(val_dataset)\nprint(f\"Validation Accuracy: {test_acc:.4f}\")\n\n# Predict on the validation set\npred_masks = model.predict(val_dataset)\n\n# Visualization\nimport matplotlib.pyplot as plt\n\ndef display_predictions(index):\n    fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n    ax[0].imshow(val_dataset.unbatch().take(1).as_numpy_iterator().next()[0])\n    ax[0].set_title(\"Original RBC Image\")\n    ax[1].imshow(val_dataset.unbatch().take(1).as_numpy_iterator().next()[1].squeeze(), cmap=\"gray\")\n    ax[1].set_title(\"Ground Truth Mask\")\n    ax[2].imshow(pred_masks[index].squeeze(), cmap=\"gray\")\n    ax[2].set_title(\"Predicted Mask\")\n    plt.show()\n\nfor i in range(3):\n    display_predictions(i)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}